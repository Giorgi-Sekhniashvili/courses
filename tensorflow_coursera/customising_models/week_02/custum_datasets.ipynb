{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.4.1'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "img_height = 28\n",
    "img_width = 28\n",
    "batch_size = 16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method 1\n",
    "## custom dataset_from_directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-1fa6256ff4f7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mseed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# if you want same stuff every time u run\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m     \u001B[0msubset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'training'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m )\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py\u001B[0m in \u001B[0;36mimage_dataset_from_directory\u001B[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001B[0m\n\u001B[0;32m    180\u001B[0m       \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    181\u001B[0m       \u001B[0mseed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 182\u001B[1;33m       follow_links=follow_links)\n\u001B[0m\u001B[0;32m    183\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mlabel_mode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'binary'\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_names\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\dataset_utils.py\u001B[0m in \u001B[0;36mindex_directory\u001B[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001B[0m\n\u001B[0;32m     63\u001B[0m   \"\"\"\n\u001B[0;32m     64\u001B[0m   \u001B[0minferred_class_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m   \u001B[1;32mfor\u001B[0m \u001B[0msubdir\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msorted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubdir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m       \u001B[0minferred_class_names\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubdir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'data/'"
     ]
    }
   ],
   "source": [
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/',            # data folder\n",
    "    labels='inferred',\n",
    "    label_mode='int',   # categorical, binary\n",
    "    # class_names = ['0', '1' ... ]\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width), #reshape if not this size\n",
    "    shuffle=True,\n",
    "    seed=1,  # if you want same stuff every time u run\n",
    "    validation_split=0.1,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/',            # data folder\n",
    "    labels='inferred',\n",
    "    label_mode='int',   # categorical, binary\n",
    "    # class_names = ['0', '1' ... ]\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width), #reshape if not this size\n",
    "    shuffle=True,\n",
    "    seed=1,  # if you want same stuff every time u run\n",
    "    validation_split=0.1,\n",
    "    subset='validation'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Augmentation the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def augment(x, y):\n",
    "    image = tf.image.random_brightness(x, max_delta=0.05)\n",
    "    return image, y\n",
    "\n",
    "ds_train.map(augment())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile and Train\n",
    "model.compile( ... ) <br>\n",
    "model.fit(train_ds, epochs=10, verbose=False) <br>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method 2\n",
    "## ImageDataGenerato and flow_from_directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=5,\n",
    "    zoom_range=(0.95, 0.95),\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.1,\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "train_generator = data_gen.flow_from_directory('data/',\n",
    "                                               target_size=(img_height, img_width),\n",
    "                                               color_mode='grayscale',\n",
    "                                               class_mode='sparse',\n",
    "                                               shuffle=True,\n",
    "                                               subset='training',\n",
    "                                               seed=1)\n",
    "\n",
    "val_generator = data_gen.flow_from_directory('data/',\n",
    "                                             target_size=(img_height, img_width),\n",
    "                                             color_mode='grayscale',\n",
    "                                             class_mode='sparse',\n",
    "                                             shuffle=True,\n",
    "                                             subset='validation',\n",
    "                                             seed=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile and Train\n",
    "model.compile( ... ) <br>\n",
    "model.fit(train_generator, epochs=10, steps_per_epoch=num_images/batch_size, verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method 3\n",
    "## from csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "labels = df['label'].values\n",
    "img_paths = df['img_paths'].values\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((img_paths, labels))\n",
    "def read_image(img_path, label):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "    # data augment here\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(read_image).map(augment).batch(batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile and Train\n",
    "model.compile( ... )\n",
    "model.fit(ds_train, epochs=10, verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}